{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JuFb1MP_O5EW",
    "outputId": "17a158d8-8df8-4af8-d8cb-b15b95e590c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mlxtend\n",
      "  Downloading mlxtend-0.23.0-py3-none-any.whl (1.4 MB)\n",
      "Requirement already satisfied: matplotlib>=3.0.0 in c:\\users\\vince\\anaconda3\\lib\\site-packages (from mlxtend) (3.5.1)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in c:\\users\\vince\\anaconda3\\lib\\site-packages (from mlxtend) (1.0.2)\n",
      "Requirement already satisfied: scipy>=1.2.1 in c:\\users\\vince\\anaconda3\\lib\\site-packages (from mlxtend) (1.7.3)\n",
      "Requirement already satisfied: pandas>=0.24.2 in c:\\users\\vince\\anaconda3\\lib\\site-packages (from mlxtend) (1.4.2)\n",
      "Requirement already satisfied: numpy>=1.16.2 in c:\\users\\vince\\anaconda3\\lib\\site-packages (from mlxtend) (1.21.5)\n",
      "Requirement already satisfied: joblib>=0.13.2 in c:\\users\\vince\\anaconda3\\lib\\site-packages (from mlxtend) (1.1.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\vince\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (1.3.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\vince\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (4.25.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\vince\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (2.8.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\vince\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (3.0.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\vince\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (9.0.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\vince\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (21.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\vince\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (0.11.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\vince\\anaconda3\\lib\\site-packages (from pandas>=0.24.2->mlxtend) (2021.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\vince\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.0.0->mlxtend) (1.16.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\vince\\anaconda3\\lib\\site-packages (from scikit-learn>=1.0.2->mlxtend) (2.2.0)\n",
      "Installing collected packages: mlxtend\n",
      "Successfully installed mlxtend-0.23.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "! pip install mlxtend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wDYkmRlZPSXY"
   },
   "source": [
    "# Association Rule for Store Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IYfOAa9fPjln"
   },
   "source": [
    "In this case study, we will explore how association rule can be used to analyze the items that are usualy purcased together.\n",
    "\n",
    "you can refer to this article to find out about apriori and association rule:\n",
    "https://rasbt.github.io/mlxtend/user_guide/frequent_patterns/apriori/\n",
    "https://rasbt.github.io/mlxtend/user_guide/frequent_patterns/association_rules/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7EOg6BIYPxt4"
   },
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gp0OZCjrQT1n"
   },
   "source": [
    "We will use the dataset of the transaction in a certain store. You can get the dataset here: \n",
    "https://gist.githubusercontent.com/Harsh-Git-Hub/2979ec48043928ad9033d8469928e751/raw/72de943e040b8bd0d087624b154d41b2ba9d9b60/retail_dataset.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "LDF65VBRQjFL",
    "outputId": "e9c6b17c-3450-4b26-af48-e963cc0dd11b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        0       1     2       3       4       5       6\n",
      "0   Bread    Wine  Eggs    Meat  Cheese  Pencil  Diaper\n",
      "1   Bread  Cheese  Meat  Diaper    Wine    Milk  Pencil\n",
      "2  Cheese    Meat  Eggs    Milk    Wine     NaN     NaN\n",
      "3  Cheese    Meat  Eggs    Milk    Wine     NaN     NaN\n",
      "4    Meat  Pencil  Wine     NaN     NaN     NaN     NaN\n"
     ]
    }
   ],
   "source": [
    "# load the data set and show the first five transaction\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "url='https://gist.githubusercontent.com/Harsh-Git-Hub/2979ec48043928ad9033d8469928e751/raw/72de943e040b8bd0d087624b154d41b2ba9d9b60/retail_dataset.csv'\n",
    "data = pd.read_csv(url)\n",
    "print(data.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IkfhUabDQup9"
   },
   "source": [
    "# Get the set of product that has been purchased\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the unique product that has been purchased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Awz6VzuMwR_-",
    "outputId": "1fc181b3-cffe-48fe-9d3b-066323061907"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Diaper' 'Pencil' nan 'Bagel' 'Cheese' 'Milk' 'Meat' 'Bread' 'Eggs'\n",
      " 'Wine']\n"
     ]
    }
   ],
   "source": [
    "unique = data[column].unique()\n",
    "print(unique)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M4g4k83bP07H"
   },
   "source": [
    "## Preprocess Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GEnL1bXtRLXe"
   },
   "source": [
    "In this step, we will transform our dataset so that we will have a one hot encoding based on the purchased products."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "N4wdVmFWQ_yg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Bagel  Bread  Cheese  Diaper  Eggs  Meat  Milk  Pencil  Wine  Bagel  ...  \\\n",
      "0      0      1       0       0     0     0     0       0     0      0  ...   \n",
      "1      0      1       0       0     0     0     0       0     0      0  ...   \n",
      "2      0      0       1       0     0     0     0       0     0      0  ...   \n",
      "3      0      0       1       0     0     0     0       0     0      0  ...   \n",
      "4      0      0       0       0     0     1     0       0     0      0  ...   \n",
      "\n",
      "   Wine  Bagel  Bread  Cheese  Diaper  Eggs  Meat  Milk  Pencil  Wine  \n",
      "0     0      0      0       0       1     0     0     0       0     0  \n",
      "1     0      0      0       0       0     0     0     0       1     0  \n",
      "2     0      0      0       0       0     0     0     0       0     0  \n",
      "3     0      0      0       0       0     0     0     0       0     0  \n",
      "4     0      0      0       0       0     0     0     0       0     0  \n",
      "\n",
      "[5 rows x 63 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(data)\n",
    "encoded = pd.get_dummies(df, prefix='', prefix_sep='')\n",
    "print(encoded.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "v67eBdxByEJX",
    "outputId": "b05c05fb-7ae1-4fbe-a01a-d6985c360f5e",
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['0' '1' '2' '3' '4' '5' '6'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[1;32mIn [45]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m columns_to_drop \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m0\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m3\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m4\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m5\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m6\u001b[39m\u001b[38;5;124m'\u001b[39m] \n\u001b[1;32m----> 2\u001b[0m new_dataframe \u001b[38;5;241m=\u001b[39m \u001b[43mencoded\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns_to_drop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(new_dataframe)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[0;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[0;32m    310\u001b[0m     )\n\u001b[1;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4954\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4806\u001b[0m \u001b[38;5;129m@deprecate_nonkeyword_arguments\u001b[39m(version\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, allowed_args\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mself\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m   4807\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrop\u001b[39m(\n\u001b[0;32m   4808\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4815\u001b[0m     errors: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   4816\u001b[0m ):\n\u001b[0;32m   4817\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4818\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[0;32m   4819\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4952\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[0;32m   4953\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4954\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   4955\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4956\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4957\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4958\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4959\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4960\u001b[0m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4961\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4962\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:4267\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4265\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m   4266\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 4267\u001b[0m         obj \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_drop_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4269\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[0;32m   4270\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:4340\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[1;34m(self, labels, axis, level, errors, consolidate, only_slice)\u001b[0m\n\u001b[0;32m   4338\u001b[0m     labels_missing \u001b[38;5;241m=\u001b[39m (axis\u001b[38;5;241m.\u001b[39mget_indexer_for(labels) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39many()\n\u001b[0;32m   4339\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m labels_missing:\n\u001b[1;32m-> 4340\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabels\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   4342\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_extension_array_dtype(mask\u001b[38;5;241m.\u001b[39mdtype):\n\u001b[0;32m   4343\u001b[0m     \u001b[38;5;66;03m# GH#45860\u001b[39;00m\n\u001b[0;32m   4344\u001b[0m     mask \u001b[38;5;241m=\u001b[39m mask\u001b[38;5;241m.\u001b[39mto_numpy(dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mbool\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['0' '1' '2' '3' '4' '5' '6'] not found in axis\""
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lBJmzWAAS4Mw"
   },
   "source": [
    "Since, the encoded dataframe consist of the empty column. We will drop the NaN column or select all columns other than the first column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "2eHZu15xyTqm",
    "outputId": "7bffff16-fc02-48fe-bc98-7616bf75908e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Bagel  Bread  Cheese  Diaper  Eggs  Meat  Milk  Pencil  Wine  Bagel  ...  \\\n",
      "0        0      1       0       0     0     0     0       0     0      0  ...   \n",
      "1        0      1       0       0     0     0     0       0     0      0  ...   \n",
      "2        0      0       1       0     0     0     0       0     0      0  ...   \n",
      "3        0      0       1       0     0     0     0       0     0      0  ...   \n",
      "4        0      0       0       0     0     1     0       0     0      0  ...   \n",
      "..     ...    ...     ...     ...   ...   ...   ...     ...   ...    ...  ...   \n",
      "310      0      1       0       0     0     0     0       0     0      0  ...   \n",
      "311      0      0       0       0     0     1     0       0     0      0  ...   \n",
      "312      0      1       0       0     0     0     0       0     0      0  ...   \n",
      "313      0      0       0       0     0     1     0       0     0      0  ...   \n",
      "314      0      0       0       0     1     0     0       0     0      0  ...   \n",
      "\n",
      "     Wine  Bagel  Bread  Cheese  Diaper  Eggs  Meat  Milk  Pencil  Wine  \n",
      "0       0      0      0       0       1     0     0     0       0     0  \n",
      "1       0      0      0       0       0     0     0     0       1     0  \n",
      "2       0      0      0       0       0     0     0     0       0     0  \n",
      "3       0      0      0       0       0     0     0     0       0     0  \n",
      "4       0      0      0       0       0     0     0     0       0     0  \n",
      "..    ...    ...    ...     ...     ...   ...   ...   ...     ...   ...  \n",
      "310     0      0      0       0       0     0     0     0       0     0  \n",
      "311     0      0      0       0       0     0     0     0       0     0  \n",
      "312     0      0      0       0       0     0     0     0       0     1  \n",
      "313     0      0      0       0       0     0     0     0       0     0  \n",
      "314     0      0      0       0       0     0     0     0       0     0  \n",
      "\n",
      "[315 rows x 63 columns]\n"
     ]
    }
   ],
   "source": [
    "new_dataframe = encoded.dropna(axis=1, how='all')\n",
    "\n",
    "# Display the new DataFrame\n",
    "print(new_dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_UXDzSNPP35P"
   },
   "source": [
    "## Apriori Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K-jD3ea4TYMV"
   },
   "source": [
    "We will use appriori algorithm to determine the frequently purchased products. \n",
    "For this case study, we will min_support=0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "BLA4Jqhoyjof",
    "outputId": "bc435206-1be2-41e6-b05b-0f1ba125e955"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequent Itemsets:\n",
      "    support itemsets\n",
      "0  0.234921  (Bread)\n",
      "\n",
      "Association Rules:\n",
      "Empty DataFrame\n",
      "Columns: [antecedents, consequents, antecedent support, consequent support, support, confidence, lift, leverage, conviction, zhangs_metric]\n",
      "Index: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vince\\anaconda3\\lib\\site-packages\\mlxtend\\frequent_patterns\\fpcommon.py:110: DeprecationWarning: DataFrames with non-bool types result in worse computationalperformance and their support might be discontinued in the future.Please use a DataFrame with bool type\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "frequent_itemsets = apriori(encoded, min_support=0.2, use_colnames=True)\n",
    "\n",
    "rules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=0.7)\n",
    "\n",
    "print(\"Frequent Itemsets:\")\n",
    "print(frequent_itemsets)\n",
    "\n",
    "print(\"\\nAssociation Rules:\")\n",
    "print(rules)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uEr2YXHrVOIA"
   },
   "source": [
    "Then, we will generate association rule of the frequent itemset based on confidence level with the threshold=0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 482
    },
    "id": "5GalSXOoy6H8",
    "outputId": "2fc5a421-bca1-41c8-f96a-e24f49280d99"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [antecedents, consequents, antecedent support, consequent support, support, confidence, lift, leverage, conviction, zhangs_metric]\n",
      "Index: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vince\\anaconda3\\lib\\site-packages\\mlxtend\\frequent_patterns\\fpcommon.py:110: DeprecationWarning: DataFrames with non-bool types result in worse computationalperformance and their support might be discontinued in the future.Please use a DataFrame with bool type\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "frequent_itemsets = apriori(encoded, min_support=0.2, use_colnames=True)\n",
    "\n",
    "rules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=0.6)\n",
    "print(rules)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Provide explanation about __antecedent support__, __consequent support__, __support__, __confidence__, __lift__, __leverage__ and __conviction__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "antecedent support = measures the proportion of transactions in the dataset that\n",
    "contain the items specified in the antecedent of a particular rule for example if the antecedent support is\n",
    "0.2 then our data contain 20% milk value.\n",
    "\n",
    "consequent support : measures the proportion of transactions in the dataset that\n",
    "contain the items specified in the consequent of a particular rule.\n",
    "\n",
    "support :measure that indicates the proportion of transactions in a dataset that contain a particular itemset (a set of items). It is one of the key metrics used to evaluate\n",
    "    the significance or frequency of a specific combination of items for example\n",
    "    in our dataset there is {milk,cheese} with 0.5 suppor then our dataset contains both 50% of milk and cheese.\n",
    "    \n",
    "confidence :measure that indicates how often a rule is found to be true. Specifically, it measures the conditional\n",
    "probability of the consequent given the antecedent in a rule.\n",
    "\n",
    "lift :lift assesses the strength of the association between the antecedent and the consequent by comparing their\n",
    "    observed co-occurrence with their expected co-occurrence under independence.\n",
    "    \n",
    "leverage : measure the difference between the observed frequency of the antecedent and the consequent occurring together\n",
    "    and the frequency that would be expectedif the antecedent and the consequent were statistically independent.\n",
    "    \n",
    "conviction : ssess the ratio of the expected frequency that the antecedent occurs without the consequent to the \n",
    "    observed frequency that the antecedent occurs without the consequent. In other words, conviction helps measure the impactof the rule on the occurrence of the consequent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
